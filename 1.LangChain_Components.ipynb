{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNA2DzEhQ4CYniNffJSmuzJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain Components\n",
        "\n",
        "LangChain is a framework designed to build applications powered by large language models (LLMs). It provides modular components that make it easier to structure, customize, and manage the flow of LLM-powered applications. The main components of LangChain are:\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Models\n",
        "Models are the core LLMs or chat models used to generate responses. LangChain provides integrations with different providers (such as OpenAI, Hugging Face, Cohere, etc.). Models can be used for text completion, chat-based interactions, embeddings, or other natural language tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Prompts\n",
        "Prompts define how information is presented to the model. A well-structured prompt helps guide the model to produce accurate and relevant results. LangChain offers:\n",
        "- **Prompt templates**: Predefined formats with placeholders.\n",
        "- **Few-shot prompting**: Including examples to improve output quality.\n",
        "- **Dynamic prompts**: Prompts that adjust based on user input or context.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Chains\n",
        "Chains are sequences of calls to models and other utilities. Instead of a single input-output call, chains allow combining multiple steps together. For example, a chain may first summarize a text, then translate it, and finally answer a question about it. Chains make workflows more structured and reusable.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Memory\n",
        "Memory allows the system to retain context across interactions. Instead of treating each query independently, memory ensures that past interactions are remembered. Types of memory include:\n",
        "- **Conversation buffer memory** (stores previous messages)\n",
        "- **Summary memory** (keeps a compressed summary of past exchanges)\n",
        "- **Vector memory** (retrieves information based on embeddings)\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Indexes\n",
        "Indexes handle storage and retrieval of external data. They are built on top of vector databases or document stores. Indexes allow the model to look up relevant documents or chunks of information when answering questions. Commonly used for retrieval-augmented generation (RAG) systems.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Agents\n",
        "Agents are components that use models to make decisions about actions. Instead of predefined chains, agents dynamically decide what steps to take based on instructions and context. Agents can:\n",
        "- Call tools (e.g., search engines, calculators, APIs).\n",
        "- Use reasoning to choose the next action.\n",
        "- Execute multi-step tasks with flexibility.\n",
        "\n",
        "---\n",
        "\n",
        "### Summary\n",
        "- **Models**: Core LLMs or embeddings.\n",
        "- **Prompts**: Instructions and templates for guiding models.\n",
        "- **Chains**: Structured workflows combining steps.\n",
        "- **Memory**: Context persistence across interactions.\n",
        "- **Indexes**: Knowledge retrieval from external sources.\n",
        "- **Agents**: Decision-making components for dynamic tasks.\n"
      ],
      "metadata": {
        "id": "oMdlZRUTYsAV"
      }
    }
  ]
}
